{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2684245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "import numpy as np\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.datasets import mnist \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63759dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tensor is an n dimensional array of data \n",
    "#vector is 1D tensor and matrix is 2D tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1340ee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor([[4.]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.515029   -0.649522    1.1850352 ]\n",
      " [-1.5125637   1.5492306   0.38609573]\n",
      " [ 0.05778437  1.0206742  -0.81093514]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor([1 3 5 7 9], shape=(5,), dtype=int32)\n",
      "tf.Tensor(46, shape=(), dtype=int32)\n",
      "tf.Tensor(46, shape=(), dtype=int32)\n",
      "tf.Tensor([  1  32 243], shape=(3,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  5.425405    -0.80187505   1.2159604    0.3933717 ]\n",
      " [-11.669405     3.601153    -0.39957464  -2.1973329 ]], shape=(2, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[  5.425405    -0.80187505   1.2159604    0.3933717 ]\n",
      " [-11.669405     3.601153    -0.39957464  -2.1973329 ]], shape=(2, 4), dtype=float32)\n",
      "tf.Tensor([6 5 4 3 2 1 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4 5 6 7 8], shape=(9,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 3 6]\n",
      " [1 4 7]\n",
      " [2 5 8]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# initialization \n",
    "x=tf.constant(4)\n",
    "print(x)\n",
    "x1=tf.constant(4, shape=(1,1), dtype=tf.float32) \n",
    "print(x1)\n",
    "x2=tf.constant([[1,2,3],[4,5,6]])\n",
    "print(x2)\n",
    "x3=tf.ones((3,3))\n",
    "print(x3)\n",
    "x4=tf.eye(3)\n",
    "print(x4)\n",
    "x5=tf.random.normal((3,3), mean=0, stddev=1) # to get normal distribution with mean =0, and standard dev=1, for uniform\n",
    "# distribution use tf.random.uniform((1,3), minval=0, maxval=1)\n",
    "print(x5)\n",
    "x6=tf.range(start=1, limit=10, delta=2) # delta is same as step\n",
    "print(x6)\n",
    "#x=tf.caast(x, dtype=tf.float64), tf.bool (casting in boolean)\n",
    "\n",
    "x=tf.constant([1,2,3])\n",
    "y=tf.constant([9,8,7])\n",
    "z=tf.add(x,y) # or z=x+, x-y, x/y, x*y\n",
    "\n",
    "z=tf.tensordot(x,y,axes=1)\n",
    "print(z)\n",
    "z=tf.reduce_sum(x*y, axis=0)\n",
    "print(z)\n",
    "z=x**5 \n",
    "print(z)\n",
    "\n",
    "x=tf.random.normal((2,3))\n",
    "y=tf.random.normal((3,4))\n",
    "z=tf.matmul(x,y)\n",
    "print(z)\n",
    "print(x@y)\n",
    "x=tf.constant([0,1,2,3,4,5,6])\n",
    "print(x[::-1]) # will print x in reverse order \n",
    "indices=tf.constant([0,3])\n",
    "x_ind=tf.gather(x,indices)\n",
    "\n",
    "x=tf.constant([[1,2],\n",
    "             [3,4],\n",
    "             [5,6]])\n",
    "print(x[0,:])\n",
    "print(x[0:2,:])\n",
    "# indexing is same as python \n",
    "\n",
    "x=tf.range(9)\n",
    "print(x)\n",
    "x=tf.reshape(x,(3,3))\n",
    "print(x)\n",
    "x=tf.transpose(x, perm=[1,0]) # inverse the axis \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535f0388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test)=mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "# here we flatten our data \n",
    "# and when we flatten we dont need to specify the input  in keras \n",
    "x_train= x_train.reshape(-1, 28*28).astype(\"float32\")/255.0\n",
    "print(x_train.shape)\n",
    "x_test= x_test.reshape(-1, 28*28).astype(\"float32\")/ 255.0\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b458e131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401,920\n",
      "Trainable params: 401,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# sequential api (only one input to one output mapping)\n",
    "# if we want to use model.summary then we have to provide keras.input \n",
    "# else we can use model.summary after fitting \n",
    "# model=keras.Sequential([\n",
    "#     keras.Input(shape=(28*28)),\n",
    "#     layers.Dense(512, activation='relu'),# fully connected layer\n",
    "#     layers.Dense(256, activation='relu'),\n",
    "#     layers.Dense(10),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "#or\n",
    "model=keras.Sequential()\n",
    "model.add(keras.Input(shape=(784)))\n",
    "model.add(layers.Dense(512, activation ='relu'))\n",
    "print(model.summary())\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "505fa596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 256)\n"
     ]
    }
   ],
   "source": [
    "# this is the step of how to debug betwen the layers or taking output after the \n",
    "# desired layer \n",
    "\n",
    "model=keras.Model(inputs=model.inputs, outputs=[model.layers[-2].output]) # for second last layer \n",
    "#model=keras.Model(inputs=model.inputs, outputs=[layer.output for layer in model.layers]\n",
    "# to get output from all of the layers \n",
    "feature=model.predict(x_train)\n",
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdaad5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi1\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 - 10s - loss: 1.9606 - accuracy: 0.6894 - 10s/epoch - 6ms/step\n",
      "Epoch 2/5\n",
      "1875/1875 - 11s - loss: 1.8127 - accuracy: 0.7442 - 11s/epoch - 6ms/step\n",
      "Epoch 3/5\n",
      "1875/1875 - 10s - loss: 1.7799 - accuracy: 0.7566 - 10s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "1875/1875 - 11s - loss: 1.7627 - accuracy: 0.7661 - 11s/epoch - 6ms/step\n",
      "Epoch 5/5\n",
      "1875/1875 - 12s - loss: 1.7522 - accuracy: 0.7709 - 12s/epoch - 6ms/step\n",
      "313/313 - 2s - loss: 1.8200 - accuracy: 0.7545 - 2s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8200291395187378, 0.7544999718666077]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "    metrics=[\"accuracy\"], )\n",
    "\n",
    " # as we didnt passes the softmax fun at last layer from_logits gonna\n",
    "#handle that \n",
    "# lr=learning rate\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2) #verbose print result after ephocs\n",
    "model.evaluate(x_test,y_test,  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "085f621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 - 10s - loss: 0.1886 - accuracy: 0.9427 - 10s/epoch - 5ms/step\n",
      "Epoch 2/5\n",
      "1875/1875 - 11s - loss: 0.0805 - accuracy: 0.9747 - 11s/epoch - 6ms/step\n",
      "Epoch 3/5\n",
      "1875/1875 - 11s - loss: 0.0542 - accuracy: 0.9830 - 11s/epoch - 6ms/step\n",
      "Epoch 4/5\n",
      "1875/1875 - 11s - loss: 0.0436 - accuracy: 0.9861 - 11s/epoch - 6ms/step\n",
      "Epoch 5/5\n",
      "1875/1875 - 11s - loss: 0.0349 - accuracy: 0.9885 - 11s/epoch - 6ms/step\n",
      "313/313 - 1s - loss: 0.0825 - accuracy: 0.9761 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08247809112071991, 0.9761000275611877]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequential api can only handle one input to one output so here we go for \n",
    "#functional api (more flexible)\n",
    "\n",
    "inputs=keras.Input(shape=(784))\n",
    "x=layers.Dense(512, activation='relu')(inputs)\n",
    "x=layers.Dense(256, activation= 'relu')(x)\n",
    "outputs = layers.Dense(10,activation='softmax')(x)\n",
    "model=keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "    metrics=[\"accuracy\"], )\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2) #verbose print result after ephocs\n",
    "model.evaluate(x_test,y_test,  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63afa0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can use optimizers other than Adam like Gradient Descent with momentum, Adagrad, and RMSprop\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7e02522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with cifar dataset \n",
    "#50000 test, 10000, 32*32 pixels rgb \n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "956128f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train),(x_test,y_test)= cifar10.load_data()\n",
    "x_train=x_train.astype(\"float32\")/255.0\n",
    "x_test= x_test.astype(\"float32\")/ 255.0\n",
    "model= keras.Sequential(\n",
    "   [\n",
    "       keras.Input(shape=(32,32,3)),# as we havent flatten it so we maintain the input shape \n",
    "       layers.Conv2D(32,3,padding='valid', activation='relu'), # it is default padding='valid'\n",
    "       # here 32 is the no. of filters, and 3 is the kernal size(3,3), padding can be valid or same\n",
    "       # in same padding output pixel is not going to change while in valid it would change \n",
    "       \n",
    "       layers.MaxPooling2D(pool_size=(2,2)),\n",
    "       #(2,2) pooling will make it half \n",
    "       layers.Conv2D(64,3,activation='relu'),\n",
    "       layers.MaxPooling2D(),\n",
    "       layers.Conv2D(128,3,activation='relu'),\n",
    "       layers.Flatten(),\n",
    "       layers.Dense(64,activation='relu'),\n",
    "       layers.Dense(10),\n",
    "   ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31476d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 32s - loss: 1.6785 - 32s/epoch - 41ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 33s - loss: 1.3551 - 33s/epoch - 43ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 35s - loss: 1.2177 - 35s/epoch - 45ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 37s - loss: 1.1157 - 37s/epoch - 47ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 38s - loss: 1.0407 - 38s/epoch - 49ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 34s - loss: 0.9804 - 34s/epoch - 44ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 34s - loss: 0.9286 - 34s/epoch - 43ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 34s - loss: 0.8785 - 34s/epoch - 44ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 34s - loss: 0.8375 - 34s/epoch - 43ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 37s - loss: 0.7963 - 37s/epoch - 47ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fbea95a1c0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(lr=3e-4)\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2048b60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f05bd5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bb8c90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5cb497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
